{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36857f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from dataset import dataset\n",
    "from model import pressureInsolesTransformer\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloading\n",
    "path_list = ['../data/subject1.pth', '../data/subject2.pth', '../data/subject3.pth', '../data/subject4.pth', '../data/subject5.pth',\n",
    "                        '../data/subject6.pth', '../data/subject7.pth', '../data/subject8.pth', '../data/subject9.pth', '../data/subject10.pth']\n",
    "data = dataset(path_list)\n",
    "batch_size = 10\n",
    "train_set, validation_set, test_set = random_split(data, [0.6, 0.2, 0.2])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "\n",
    "    for data, label in iter(loader):\n",
    "        data = data.permute((0,2,1)).to(torch.float32).to(device)\n",
    "        label = label.to(device).to(torch.long)\n",
    "        print(label.shape)\n",
    "        print(label.dtype)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        print(outputs.shape)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        \n",
    "    return running_loss\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, best_loss=float('inf'), save_path=\"best_model.pth\"):\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in iter(loader):\n",
    "            data = data.permute((0,2,1)).to(torch.float32).to(device)\n",
    "            label = label.to(device).to(torch.long)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, label)\n",
    "            running_loss.append(loss.item())\n",
    "    val_loss = sum(running_loss)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    return running_loss, best_loss\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device):\n",
    "    best_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss, best_loss = validate(model, val_loader, criterion, device, best_loss, save_path=\"best_autoencoder.pth\")\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {sum(train_loss):.4f}\"\n",
    "              f\"| Val Loss: {sum(val_loss):.4f}\", end=\"\\r\")\n",
    "    return train_losses\n",
    "\n",
    "def reinit_transformer_weights(model, d_model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            nn.init.xavier_uniform_(module.in_proj_weight)\n",
    "            if module.in_proj_bias is not None:\n",
    "                nn.init.zeros_(module.in_proj_bias)\n",
    "\n",
    "            nn.init.xavier_uniform_(module.out_proj.weight)\n",
    "            if module.out_proj.bias is not None:\n",
    "                nn.init.zeros_(module.out_proj.bias)\n",
    "\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=1/math.sqrt(d_model))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"mps\")\n",
    "    epochs = 200\n",
    "    \n",
    "    model = pressureInsolesTransformer(\n",
    "    input_dim=302,\n",
    "    latent_dim=32,\n",
    "    num_classes=10,\n",
    "    num_encoder_layers=6,\n",
    "    nhead=16,\n",
    "    dim_feedforward=1024,\n",
    "    dropout=0.3,\n",
    "    seq_len=287\n",
    "    )\n",
    "    reinit_transformer_weights(model, 1024)\n",
    "    model.to(device)   \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.2)\n",
    "    scheduler1 = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=20)\n",
    "    scheduler2 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "    scheduler = optim.lr_scheduler.SequentialLR(optimizer, [scheduler1, scheduler2], [21])\n",
    "    train_losses, val_losses = train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e377324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "print([sum(x)/len(x) for x in train_losses])\n",
    "print([sum(x)/len(x) for x in val_losses])\n",
    "plt.plot([sum(x)/len(x) for x in train_losses])\n",
    "plt.plot([sum(x)/len(x) for x in val_losses])\n",
    "print(min([sum(x)/len(x) for x in val_losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test_model(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in iter(test_loader):\n",
    "        data = data.permute((0,2,1)).to(torch.float32).to(device)\n",
    "        labels = labels.to(device).to(torch.long)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return correct / total\n",
    "        \n",
    "\n",
    "model_path = \"./best_model.pth\"\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    accuracy = test_model(model, test_loader)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
